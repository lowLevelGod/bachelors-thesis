\chapter{Compararea modelelor finale}

În final, antrenăm fiecare tip de model cu hiperparametrii optimi găsiţi 
folosind setul de validare şi folosim setul de testare pentru a evalua
imparţial modelele finale.

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{
        |X
        |X
        |X
        |X
        |X|
    }
    \hline
    {Model} & {Accuracy} & {Recall} & {Precision} & {F1 Score} \\
    \hline
    \rowcolor{gray!20} \text{OCSVM} & 0.817 & 0.638 & 0.585 & 0.610 \\
    \text{GMM} & 0.865 & 0.735 & 0.505 & 0.599 \\
    \rowcolor{gray!20} \text{KDE} & 0.863 & 0.731 & 0.502 & 0.596 \\
    \hline
    \end{tabularx}
    \caption{Performanţa maximă, în funcţie de F1, a fiecărui model pe setul de testare}
\end{table}

Cele 2 modele care au o performanţă similară sunt Gaussian Mixture Model și Kernel Density Estimation,
ultimul având o valoare puţin mai mică pentru F1 score faţă de cel din urmă, dar cu un timp de antrenare 
mult mai mare. Kernel Density Estimation este de departe un model nepotrivit 
pentru acest set de date, necesitând un timp crescut de antrenare pentru 
niște rezultate mediocre. 

Precision este scăzut şi prin urmare şi 
f1 score este scăzut. În schimb, recall are o valoare mai ridicată pentru toate modelele. Acest 
fapt ne arată că detectăm o cantitate mare de anomalii, dar în acelaşi timp, semnalăm un număr 
mare de tranzacţii obişnuite ca fiind frauduloase. Acest lucru poate deveni un inconvenient 
pentru client în cazul în care tranzacţia este anulată ca urmare a raportării incorecte.

Gaussian Mixture Model a fost modelul cu valoarea cea mai mare pentru f1 score
pentru setul de validare, chiar dacă nu este 
un model la fel de complex precum celelalte 2 tehnici nesupervizate. De asemenea, 
acesta a necesitat doar 3 minute pentru
antrenare şi prezicere a etichetelor, dar a produs rezultate mai bune decât
One class SVM şi decât Kernel Density Estimation care au avut nevoie de o perioada
îndelungată pentru antrenare şi căutare a hiperparametrilor optimi.

Totuşi, pe setul de test, One Class SVM este cel care obţine cel mai mare f1 score.

Ilustrăm şi curba ROC alături de metrica AUC pentru modelele finale. Cu cât graficul 
tinde să se lipească de colţul stânga sus, cu atât aria de sub grafic creşte rezultând 
într-o performanţă mai bună. Linia punctată pe diagonală 
din fiecare diagramă reprezintă graficul produs de clasificatorul aleatoriu şi are rolul
de a marca marginea inferioară a performanţei faţă de această metrică. De asemenea, este 
de menţionat că dacă graficul se află sub linia diagonală, atunci am trage concluzia că
algoritmul nostru este inutil. Totuşi, putem inversa clasa negativă cu cea pozitivă şi 
astfel obţinem simetricul graficului faţă de diagonală care acum, evident, se află deasupra
liniei. Prin urmare, distanţa între grafic şi linie este o măsură mai relevantă decât poziţia
relativă. Se presupune că operaţia de aplicare a simetricului este folosită unde este cazul 
pentru diagramele de mai jos.

Curba ROC are nevoie ori de probabilităţi ori de valori ce exprimă încrederea pentru fiecare 
prezicere, fără aplicarea vreunui prag. Kernel Density Esimation şi Gaussian Mixture Model 
produc deja probabilităţi, pe când One Class SVM nu produce decât distanţa faţă de hiperplanul
de separare. Totuşi, vom folosi un truc pentru a transforma rezultatele OCSVM în valori 
de încredere \cite{stackoverflow-auc}. Înlocuim fiecare valoare cu valoarea respectivă scăzută din valoarea maximă
dată de funcţia de decizie după cum urmează:

$$y_{score} = MAX - f(y)$$
unde 

\begin{itemize}
    \item $y_{score}$ este valoarea folosită pentru curba ROC
    \item $MAX$ este $\underset{i=1,\dots,N}{\max} f(y_{i})$ pentru $N$ observaţii
    \item $f$ este funcţia de decizie 
\end{itemize}

Astfel, putem compara modelele finale folosind şi metrica AUC care ne 
indică cât de robust este un model, indiferent de pragul ales pentru 
o anumită problemă. Clasamentul este acelaşi şi aici,
cu One Class SVM fiind cel mai performant, urmat de Gaussian Mixture
Model, iar Kernel Density Estimation la coadă.

În concluzie, \textbf{One Class SVM} este modelul cel mai bun cu \textbf{f1 score}
de 0.61 şi 
\textbf{AUC} de 0.91 pe setul de test, 
dar Gaussian Mixture Model este şi el un candidat
bun datorită vitezei de antrenare şi inferenţă.

\begin{figure}[!htb] % Use a separate page for the figure
    \begin{minipage}[t]{0.5\textwidth}
        \vspace{0pt}
        \includegraphics[width=\textwidth]{images/kde-roc.pdf}
        \caption{Curba ROC pentru KDE} 
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.5\textwidth}
        \vspace{0pt}
        \includegraphics[width=\textwidth]{images/gmm-roc.pdf}
        \caption{Curba ROC pentru GMM}
    \end{minipage}
    
    \begin{minipage}[t]{1\textwidth}
       \centering
        \includegraphics[width=\textwidth]{images/ocsvm-roc.pdf}
        \caption{Curba ROC pentru OCSVM}
    \end{minipage}
    
\end{figure}

\noindent